{% extends "layouts/base.html" %}

{% block title %} Dashboard {% endblock %}

<!-- Specific Page CSS goes HERE  -->
{% block stylesheets %}{% endblock stylesheets %}

{% block content %}

<div class="row">
  <div class="col-12">
    <div class="card card-chart">
      <div class="card-header">
        <h5 class="card-category">Se√±al de Audio</h5>
        <h3 class="card-title"><i class="tim-icons icon-bell-55 text-primary"></i> Dominio del Tiempo</h3>
      </div>
      <div class="card-body">
        <div class="chart-area">
          <canvas id="chartLinePurple"></canvas>
        </div>
      </div>
    </div>
  </div>
  
</div>

<div class="row">
  <div>
    <p class="decibelios"></p>
  </div>
  <audio id="audioRecorder" controls autoplay style="display: none"></audio>

  <div>
    <span id="errorMsg"></span>
  </div>
</div>
{% endblock content %}

<!-- Specific Page JS goes HERE  -->
{% block javascripts %}

<script>
  $(document).ready(function () {
    // Javascript method's body can be found in assets/js/demos.js
    demo.initDashboardPageCharts();

  });
</script>

<script type="text/javascript">
  /*
   *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
   *
   *  Use of this source code is governed by a BSD-style license
   *  that can be found in the LICENSE file in the root of the source
   *  tree.
   */

  'use strict';

  var visualSetting = "sinewave";


  var canvas_time = document.querySelector('#chartLinePurple');
  var canvas_ctx_time = canvas_time.getContext("2d");
  var intendedWidth_time = document.querySelector('.chart-area').clientWidth;

  canvas_time.setAttribute('width', intendedWidth_time);
  var drawVisual;

  //initialize();
  var webaudio_tooling_obj = function () {

    var audioContext

    console.log("audio is starting up ...");

    var BUFF_SIZE_RENDERER = 16384;

    var audioInput = null,
      microphone_stream = null,
      gain_node = null,
      script_processor_node = null,
      script_processor_analysis_node = null,
      analyser_node = null;

    if (!navigator.getUserMedia)
      navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia ||
      navigator.mozGetUserMedia || navigator.msGetUserMedia;

    if (navigator.getUserMedia) {

      navigator.getUserMedia({
          audio: true
        },
        function (stream) {
          start_microphone(stream);
        },
        function (e) {
          alert('Error capturing audio.');
        }
      );

    } else {
      alert('getUserMedia not supported in this browser.');
    }

    // ---

    function show_some_data(given_typed_array, num_row_to_display, label) {

      var size_buffer = given_typed_array.length;
      var index = 0;

      console.log("__________ " + label);

      if (label === "time") {

        for (; index < num_row_to_display && index < size_buffer; index += 1) {
          //console.log(given_typed_array[index])
          var curr_value_time = (given_typed_array[index] / 128) - 1.0;
          //console.log(curr_value_time);
          advance(curr_value_time);
        }

      } else if (label === "frequency") {

        for (; index < num_row_to_display && index < size_buffer; index += 1) {

          console.log(given_typed_array[index]);
        }

      } else {

        throw new Error("ERROR - must pass time or frequency");
      }
    }

    function process_microphone_buffer(event) {

      var i, N, inp, microphone_output_buffer;

      microphone_output_buffer = event.inputBuffer.getChannelData(0); // just mono - 1 channel for now
    }

    function getAverageVolume(array) {
          var values = 0;
          var average;

          var length = array.length;

          // get all the frequency amplitudes
          for (var i = 0; i < length; i++) {
            values += array[i];
          }

          average = values / length;
          return average;
        }


    function visualize() {
      var WIDTH_time = canvas_time.width;

      var HEIGHT_time = canvas_time.height;

      if (visualSetting === "sinewave") {
        analyser_node.fftSize = 2048;
        var buffer_length = analyser_node.fftSize;
        //console.log(buffer_length);
        var array_time_domain = new Uint8Array(buffer_length);


        canvas_ctx_time.clearRect(0, 0, WIDTH_time, HEIGHT_time);

        var draw_time_audio = function () {

          drawVisual = requestAnimationFrame(draw_time_audio);

          analyser_node.getByteTimeDomainData(array_time_domain);


          canvas_ctx_time.fillStyle = 'rgb(200, 200, 200)';
          canvas_ctx_time.fillRect(0, 0, WIDTH_time, HEIGHT_time);

          canvas_ctx_time.lineWidth = 2;
          canvas_ctx_time.strokeStyle = 'rgb(0, 0, 0)';

          canvas_ctx_time.beginPath();

          var sliceWidth = WIDTH_time * 1.0 / buffer_length;
          var x = 0;

          for (var i = 0; i < buffer_length; i++) {

            var v = array_time_domain[i] / 256.0;
            document.getElementsByClassName("decibelios").innerHTML = v
            var y = v * HEIGHT_time;

            if (i === 0) {
              canvas_ctx_time.moveTo(x, y);
            } else {
              canvas_ctx_time.lineTo(x, y);
            }

            x += sliceWidth;
          }

          canvas_ctx_time.lineTo(canvas_time.width, canvas_time.height);
          canvas_ctx_time.stroke();
        };

        draw_time_audio();

      }

    }


    function start_microphone(stream) {
      audioContext = new AudioContext();
      gain_node = audioContext.createGain();
      gain_node.connect(audioContext.destination);

      microphone_stream = audioContext.createMediaStreamSource(stream);
      microphone_stream.connect(gain_node);

      script_processor_node = audioContext.createScriptProcessor(BUFF_SIZE_RENDERER, 1, 1);
      script_processor_node.onaudioprocess = process_microphone_buffer;

      microphone_stream.connect(script_processor_node);

      // --- enable volume control for output speakers
      /*
              document.getElementById('volume').addEventListener('change', function () {

                var curr_volume = this.value;
                gain_node.gain.value = curr_volume;

                console.log("curr_volume ", curr_volume);
              });*/

      // --- setup FFT

      script_processor_analysis_node = audioContext.createScriptProcessor(2048, 1, 1);
      script_processor_analysis_node.connect(gain_node);

      analyser_node = audioContext.createAnalyser();
      analyser_node.smoothingTimeConstant = 0;
      //analyser_node.fftSize = 2048;

      microphone_stream.connect(analyser_node);

      analyser_node.connect(script_processor_analysis_node);


      visualize();

      script_processor_analysis_node.onaudioprocess = function () {

        // get the average for the first channel
        //analyser_node.getByteFrequencyData(array_freq_domain);
        //analyser_node.getByteTimeDomainData(array_time_domain);

        // draw the spectrogram

          // get the average, bincount is fftsize / 2




        if (microphone_stream.playbackState == microphone_stream.PLAYING_STATE) {

          //show_some_data(array_freq_domain, 5, "frequency");

          //show_some_data(array_time_domain, 50,
          //  "time"); // store this to record to aggregate buffer/file
        }
      };
    }

  }(); //  webaudio_tooling_obj = function()
</script>

{% endblock javascripts %}